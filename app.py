import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import urllib.parse
import io

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ í¬ë¡¤ëŸ¬",
    page_icon="ğŸ”",
    layout="wide"
)

def crawl_naver_blog(search_keyword, max_results=20):
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ í¬ë¡¤ë§"""
    
    # ê²€ìƒ‰ì–´ URL ì¸ì½”ë”©
    encoded_keyword = urllib.parse.quote(search_keyword)
    url = f"https://search.naver.com/search.naver?ssc=tab.blog.all&sm=tab_jum&query={encoded_keyword}"
    
    # í—¤ë” ì„¤ì •
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    try:
        # ì›¹í˜ì´ì§€ ìš”ì²­
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        # HTML íŒŒì‹±
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë°ì´í„° ìˆ˜ì§‘
        user_info_elements = soup.select('.user_info')[:max_results]
        
        # user_info ì•ˆì˜ ì²« ë²ˆì§¸ sub í´ë˜ìŠ¤ë§Œ ìˆ˜ì§‘
        sub_elements = []
        for user_info in user_info_elements:
            first_sub = user_info.select_one('.sub')
            if first_sub:
                sub_elements.append(first_sub)
        
        title_area_elements = soup.select('.title_area')[:max_results]
        dsc_area_elements = soup.select('.dsc_area')[:max_results]
        
        # ì˜¤ëŠ˜ ë‚ ì§œ
        today = datetime.now().strftime('%Y-%m-%d')
        
        # ê²°ê³¼ ë°ì´í„°
        results = []
        
        # ìµœëŒ€ ê¸¸ì´ ê²°ì •
        max_length = max(
            len(user_info_elements),
            len(sub_elements), 
            len(title_area_elements),
            len(dsc_area_elements)
        )
        
        for i in range(min(max_length, max_results)):
            # ë¸”ë¡œê·¸ëª… ì¶”ì¶œ
            blog_name = ""
            if i < len(user_info_elements):
                name_element = user_info_elements[i].select_one('.name')
                blog_name = name_element.get_text(strip=True) if name_element else ""
            
            # ê²Œì‹œì¼ ì¶”ì¶œ
            post_date = ""
            if i < len(sub_elements):
                post_date = sub_elements[i].get_text(strip=True)
            
            # íƒ€ì´í‹€ ì¶”ì¶œ
            title = ""
            if i < len(title_area_elements):
                title = title_area_elements[i].get_text(strip=True)
            
            # ë””ìŠ¤í¬ë¦½ì…˜ê³¼ ë§í¬ ì¶”ì¶œ
            description = ""
            link = ""
            is_ad = "N"
            if i < len(dsc_area_elements):
                description = dsc_area_elements[i].get_text(strip=True)
                links = dsc_area_elements[i].select('a[href]')
                if links:
                    link_urls = [a.get('href', '') for a in links]
                    link = ' | '.join(link_urls)
                    # ê´‘ê³  íŒë³„
                    if any(url.startswith('https://ader.naver.com/') for url in link_urls):
                        is_ad = "Y"
            
            # user_info ë§í¬ë„ ê´‘ê³  ì²´í¬
            if i < len(user_info_elements):
                name_element = user_info_elements[i].select_one('.name')
                if name_element:
                    name_href = name_element.get('href', '')
                    if name_href.startswith('https://ader.naver.com/'):
                        is_ad = "Y"
            
            # ê²°ê³¼ ì¶”ê°€
            results.append({
                'ë‚ ì§œ': today,
                'ê²€ìƒ‰ì–´': search_keyword,
                'ë…¸ì¶œìˆœìœ„': i + 1,
                'ë¸”ë¡œê·¸ëª…': blog_name,
                'íƒ€ì´í‹€': title,
                'ë””ìŠ¤í¬ë¦½ì…˜': description,
                'ê²Œì‹œì¼': post_date,
                'ê´‘ê³ ì—¬ë¶€': is_ad,
                'ë§í¬': link
            })
        
        return results, None
        
    except Exception as e:
        return None, str(e)

def main():
    """ë©”ì¸ ì›¹ì•±"""
    
    # ì œëª©
    st.title("ğŸ” ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ í¬ë¡¤ëŸ¬")
    st.markdown("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ë©´ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë¡¤ë§í•´ì„œ CSVë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ì‚¬ì´ë“œë°”
    st.sidebar.header("âš™ï¸ ì„¤ì •")
    
    # ê²€ìƒ‰ì–´ ì…ë ¥
    search_keyword = st.text_input(
        "ğŸ” ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ì˜ˆ: ì˜¨ë¦¬í”„ì˜ì›",
        help="ë„¤ì´ë²„ ë¸”ë¡œê·¸ì—ì„œ ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
    )
    
    # ê²°ê³¼ ê°œìˆ˜ ì„ íƒ
    max_results = st.sidebar.selectbox(
        "ğŸ“Š í¬ë¡¤ë§í•  ê²°ê³¼ ê°œìˆ˜:",
        [10, 20, 30, 50],
        index=1  # ê¸°ë³¸ê°’ 20
    )
    
    # ê²€ìƒ‰ ë²„íŠ¼
    if st.button("ğŸš€ í¬ë¡¤ë§ ì‹œì‘", type="primary"):
        if not search_keyword.strip():
            st.error("âŒ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return
        
        # ë¡œë”© í‘œì‹œ
        with st.spinner(f"'{search_keyword}' ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë¡¤ë§ ì¤‘..."):
            results, error = crawl_naver_blog(search_keyword.strip(), max_results)
        
        if error:
            st.error(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error}")
            return
        
        if not results:
            st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê²°ê³¼ í‘œì‹œ
        st.success(f"âœ… ì´ {len(results)}ê°œì˜ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")
        
        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame(results)
        
        # í†µê³„ ì •ë³´
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì „ì²´ ê²°ê³¼", len(results))
        
        with col2:
            ad_count = len(df[df['ê´‘ê³ ì—¬ë¶€'] == 'Y'])
            st.metric("ê´‘ê³  ê²Œì‹œë¬¼", ad_count)
        
        with col3:
            normal_count = len(df[df['ê´‘ê³ ì—¬ë¶€'] == 'N'])
            st.metric("ì¼ë°˜ ê²Œì‹œë¬¼", normal_count)
        
        with col4:
            if len(results) > 0:
                ad_ratio = round((ad_count / len(results)) * 100, 1)
                st.metric("ê´‘ê³  ë¹„ìœ¨", f"{ad_ratio}%")
        
        # ë°ì´í„° í…Œì´ë¸” í‘œì‹œ
        st.subheader("ğŸ“‹ í¬ë¡¤ë§ ê²°ê³¼")
        
        # í•„í„° ì˜µì…˜
        filter_option = st.selectbox(
            "í•„í„°:",
            ["ì „ì²´", "ì¼ë°˜ ê²Œì‹œë¬¼ë§Œ", "ê´‘ê³ ë§Œ"]
        )
        
        if filter_option == "ì¼ë°˜ ê²Œì‹œë¬¼ë§Œ":
            filtered_df = df[df['ê´‘ê³ ì—¬ë¶€'] == 'N']
        elif filter_option == "ê´‘ê³ ë§Œ":
            filtered_df = df[df['ê´‘ê³ ì—¬ë¶€'] == 'Y']
        else:
            filtered_df = df
        
        # í…Œì´ë¸” í‘œì‹œ
        st.dataframe(
            filtered_df,
            use_container_width=True,
            hide_index=True
        )
        
        # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        csv_buffer = io.StringIO()
        df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        csv_data = csv_buffer.getvalue()
        
        filename = f"naver_blog_search_{search_keyword}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        
        st.download_button(
            label="ğŸ“¥ CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=csv_data,
            file_name=filename,
            mime="text/csv",
            type="primary"
        )
        
        # ë¯¸ë¦¬ë³´ê¸°
        st.subheader("ğŸ‘€ ìƒìœ„ 3ê°œ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        for i, result in enumerate(results[:3]):
            ad_badge = "ğŸ”´ ê´‘ê³ " if result['ê´‘ê³ ì—¬ë¶€'] == "Y" else "ğŸŸ¢ ì¼ë°˜"
            with st.expander(f"{i+1}ìˆœìœ„ {ad_badge}: {result['ë¸”ë¡œê·¸ëª…']}"):
                st.write(f"**ì œëª©:** {result['íƒ€ì´í‹€']}")
                st.write(f"**ì„¤ëª…:** {result['ë””ìŠ¤í¬ë¦½ì…˜'][:100]}...")
                st.write(f"**ê²Œì‹œì¼:** {result['ê²Œì‹œì¼']}")
                if result['ë§í¬']:
                    st.write(f"**ë§í¬:** {result['ë§í¬']}")

if __name__ == "__main__":
    main()